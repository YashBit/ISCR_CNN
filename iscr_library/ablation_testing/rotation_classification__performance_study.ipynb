{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Purpose of Document:\n",
        "\n",
        "1. See how different versions of ResNet compare and drop in performance with rotations of certain images\n",
        "\n",
        "2. Davida's Number Images"
      ],
      "metadata": {
        "id": "uZPHg6cG9tlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNOzXGt9Heil",
        "outputId": "105eb204-13a1-4080-cdc0-2d86485ff2aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### LIBRARY IMPORTS\n",
        "from google.colab import files\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "LGrsT6ZtHgrT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOx1MOeqHiuB",
        "outputId": "7e491ec4-c06b-4d34-f066-dc2fb280cf4f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5GKCC7iHJRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  ALGORITHM:\n",
        "\n",
        "  1. We have the truth label\n",
        "  2. I want to see the confidence of the model dropping when given a different orientation of that image\n",
        "  3. See the differences when you freeze different layers of resnet 18 in the confidence dropping\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UI8XSRsrHJsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "# Generate labels from A to Z\n",
        "letters = list(string.ascii_uppercase)\n",
        "\n",
        "# Generate numbers from 0 to 9\n",
        "numbers = list(range(10))\n",
        "\n",
        "# Combine letters and numbers\n",
        "all_labels = letters + numbers\n",
        "\n",
        "# Create label mapping\n",
        "label_mapping = {label: idx for idx, label in enumerate(all_labels)}\n",
        "\n",
        "print(label_mapping)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNFLC-BU_h6L",
        "outputId": "6d9b1d4c-e9d7-4643-931a-1c5afccd9636"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 0: 26, 1: 27, 2: 28, 3: 29, 4: 30, 5: 31, 6: 32, 7: 33, 8: 34, 9: 35}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load pretrained ResNet-18\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def get_image_confidence(model, image_path, true_label):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    input_tensor = transform(img).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "\n",
        "        # Convert true_label to its corresponding index using label_mapping\n",
        "        if true_label.isdigit():\n",
        "          true_label = int(true_label)\n",
        "        elif true_label.islower():\n",
        "          true_label = true_label.upper()\n",
        "\n",
        "        target_index = label_mapping[true_label]\n",
        "\n",
        "        confidence = probabilities[0][target_index].item()\n",
        "    return confidence\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXVBWSBSiHOJ",
        "outputId": "57021a00-e1cd-44f7-d5c1-2ea0c56e5ded"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = \"/content/drive/MyDrive/iscr_image_dataset/letter_number_images_multi_fonts\""
      ],
      "metadata": {
        "id": "GH-Lff04VnYn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = r'^([A-Z])_(1|2|3|4|5)(_\\d{1,3})?\\.png$'\n",
        "\n",
        "def sorting_key(img):\n",
        "    match = re.match(pattern, img)\n",
        "    if not match:\n",
        "        return None\n",
        "    alphabet = match.group(1)\n",
        "    classname = int(match.group(2))\n",
        "    orientation = int(match.group(3).replace(\"_\", \"\")) if match.group(3) else 0\n",
        "    return (alphabet, classname, orientation)\n",
        "\n",
        "# Filter based on regex and then sort\n",
        "all_files = os.listdir(folder_path)\n",
        "sorted_files = sorted((file_name for file_name in all_files if sorting_key(file_name)), key=sorting_key)\n",
        "\n",
        "\n",
        "print(len(sorted_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNXIBHtJKjLE",
        "outputId": "b6192246-644a-41ee-b767-d4f95ea31bbd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for file_name in os.listdir(folder_path):\n",
        "  if count < 100:\n",
        "    print(file_name)\n",
        "    count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKxm-o35PuPr",
        "outputId": "026e8e7f-d6e2-4b6b-d91e-7c8936372c28"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A_9_100.png\n",
            "V_4_260.png\n",
            "O_7_340.png\n",
            "O_6_100.png\n",
            "6_1_120.png\n",
            "A_8_40.png\n",
            "T_6_260.png\n",
            "T_7_160.png\n",
            "small_p_9_80.png\n",
            "small_g_4_100.png\n",
            "T_7_340.png\n",
            "T_10_160.png\n",
            "T_7_40.png\n",
            "V_4_300.png\n",
            "small_c_1_340.png\n",
            "V_4_240.png\n",
            "small_a_3_300.png\n",
            "T_7_300.png\n",
            "K_3_60.png\n",
            "Z_8_160.png\n",
            "small_p_9_60.png\n",
            "4_3_200.png\n",
            "V_4_180.png\n",
            "V_5_260.png\n",
            "T_6_240.png\n",
            "small_c_1_200.png\n",
            "M_5_360.png\n",
            "4_3_320.png\n",
            "Z_8_60.png\n",
            "X_10_20.png\n",
            "T_7_200.png\n",
            "small_z_2_260.png\n",
            "X_10_100.png\n",
            "4_3_140.png\n",
            "small_a_3_180.png\n",
            "small_c_1_40.png\n",
            "A_8_300.png\n",
            "small_p_9_140.png\n",
            "R_1_240.png\n",
            "T_7_360.png\n",
            "small_z_2_80.png\n",
            "X_10_140.png\n",
            "4_3_360.png\n",
            "M_5_20.png\n",
            "6_1_80.png\n",
            "small_z_2_120.png\n",
            "small_a_2_320.png\n",
            "A_9_180.png\n",
            "6_1_20.png\n",
            "O_7_260.png\n",
            "small_z_3_280.png\n",
            "A_9_360.png\n",
            "O_6_240.png\n",
            "small_a_3_160.png\n",
            "V_5_180.png\n",
            "small_g_4_140.png\n",
            "O_7_100.png\n",
            "4_3_40.png\n",
            "6_1_340.png\n",
            "A_8_200.png\n",
            "O_6_260.png\n",
            "small_g_4_340.png\n",
            "small_p_9_200.png\n",
            "O_6_340.png\n",
            "R_1_100.png\n",
            "V_4_320.png\n",
            "T_10_180.png\n",
            "O_6_140.png\n",
            "V_4_20.png\n",
            "T_6_200.png\n",
            "A_8_220.png\n",
            "small_a_3_240.png\n",
            "A_9_220.png\n",
            "small_g_4_40.png\n",
            "K_3_160.png\n",
            "T_6_140.png\n",
            "small_z_2_200.png\n",
            "6_1_100.png\n",
            "T_10_240.png\n",
            "V_5_300.png\n",
            "Z_8_20.png\n",
            "M_5_220.png\n",
            "small_c_1_60.png\n",
            "A_9_120.png\n",
            "K_3_280.png\n",
            "small_z_3_200.png\n",
            "Z_8_360.png\n",
            "M_5_260.png\n",
            "small_a_3_360.png\n",
            "small_c_1_120.png\n",
            "V_5_280.png\n",
            "V_4_160.png\n",
            "6_1_60.png\n",
            "R_1_60.png\n",
            "small_p_9_240.png\n",
            "T_10_40.png\n",
            "R_1_300.png\n",
            "T_7_280.png\n",
            "A_8_260.png\n",
            "V_5_60.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_pattern = r'^(small_[a-z]+|[\\dA-Z]+)_(1|2)(_\\d{2,}|_[1-9])?\\.png$'\n",
        "\n",
        "def sorting_key(img):\n",
        "    match = re.match(pattern, img)\n",
        "    if not match:\n",
        "      return None\n",
        "    classname = int(match.group(2))\n",
        "    orientation = int(match.group(3).replace(\"_\", \"\")) if match.group(3) else 0\n",
        "    return (classname, orientation)\n",
        "\n",
        "sorted_images = sorted(filtered_images, key=sorting_key)\n",
        "\n",
        "print(sorted_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "W8NkZ-M6KlAs",
        "outputId": "64c1eb4a-4800-4152-a5fb-4bf7eac147a6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2f6248956cb8>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclassname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msorted_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorting_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RegEx Pattern\n",
        "\n",
        "for file_name in os.listdir(folder_path):\n",
        "  match = re.match(pattern, file_name)\n",
        "  if match:\n",
        "    label = match.group(2)\n",
        "    if match.group(3):  # if orientation is present\n",
        "        orientation = int(match.group(3).replace(\"_\", \"\"))\n",
        "    else:\n",
        "        orientation = 0  # default orientation\n",
        "    image_path = os.path.join(folder_path, file_name)\n",
        "    confidence = get_image_confidence(model, image_path, label)  # Adjust function to use label appropriately\n",
        "\n",
        "    if file_name not in results:\n",
        "        results[file_name] = {}\n",
        "    results[file_name][orientation] = confidence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "b37HaPWIlpj9",
        "outputId": "04a0264c-26e7-4c6f-bc3c-4800a1e3e233"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-59ff9f64d4e3>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0morientation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# default orientation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mconfidence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Adjust function to use label appropriately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-bbaaa35b15bc>\u001b[0m in \u001b[0;36mget_image_confidence\u001b[0;34m(model, image_path, true_label)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_image_confidence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WE WILL DO THIS FOR 100 IMAGES ONLY:\n",
        "\n"
      ],
      "metadata": {
        "id": "wNwShTqm_hGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDDwzijenLSw",
        "outputId": "8c4cc7d0-f67d-4a41-8e5e-d23937a8cecc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(orientations, avg_confidences)\n",
        "plt.xlabel('Rotation Angle')\n",
        "plt.ylabel('Model Confidence')\n",
        "plt.title('Model Confidence vs. Image Rotation')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Q9ILatFsiEF-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}